{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-historic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://norvig.com/big.txt; mv big.txt train_texts_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "words_occurences = Counter(words(open('train_texts_en.txt').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(word, total_occurences=sum(words_occurences.values())):\n",
    "    '''Probability of `word`. Naive implementation.'''\n",
    "    return words_occurences[word] / total_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_candidates(words):\n",
    "    '''The subset of `words` that appear in the dictionary of words_occurences.'''\n",
    "    output = set()\n",
    "    for word in words:\n",
    "        if word in words_occurences:\n",
    "            output.add(word)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    '''All edits that are one edit away from `word`.'''\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    # <YOUR CODE: generate various candidates>\n",
    "    deletes = [L + R[1:] for L, R in splits]\n",
    "    transposes = [L[:-1] + R[0] + L[-1] + R[1:] for L, R in splits if len(L) > 0 and len(R) > 0]\n",
    "    replaces = [L + c + R[1:] for L, R in splits for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    '''All edits that are 2 edits away from `word`.'''\n",
    "    #<YOUR CODE>\n",
    "    output = set()\n",
    "    for candidate in edits1(word):\n",
    "        output.update(edits1(candidate))\n",
    "    return output\n",
    "\n",
    "def generate_candidates(word):\n",
    "    '''Generate possible spelling corrections for word: 2 edits away is enough.'''\n",
    "    #<YOUR CODE>\n",
    "    return limit_candidates(edits2(word)) or limit_candidates(edits1(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"mestak\"\n",
    "assert type(generate_candidates(word)) == set\n",
    "assert generate_candidates(word) == {'meatal', 'mental', 'mesial', 'metal', 'mistake', 'vestas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_word(word):\n",
    "    '''Most probable spelling correction for word.'''\n",
    "    return max(generate_candidates(word), key=language_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistake'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"mestak\"\n",
    "correct_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanislav.petrov/.venvs/spell/lib64/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    \"пквкая чейчс погаа\",\n",
    "    \"как проайти ло музея\",\n",
    "    \"как папасть на сайт однакласники\",\n",
    "    \"кто еапичл картмну зевденая очь\",\n",
    "    \"прийдя в МГТУ я был удивлен никого необноружив там...\",\n",
    "    \"Думю ешцъа лет череа 10 ретроспективно просматривотьэ то будкетцц мне невероя тна ин те р но\",\n",
    "    \"crjkmrj ctqxfc dhtvtyb\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "used_time = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Pavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q deeppavlov\n",
    "# !python -m deeppavlov install levenshtein_corrector_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "\n",
    "model = build_model('levenshtein_corrector_ru', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                  | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 21.62it/s]\n"
     ]
    }
   ],
   "source": [
    "t_start = time.perf_counter()\n",
    "results[\"deep_pavlov\"] = {sample: model([sample])[0] for sample in tqdm(samples)}\n",
    "cpu_time = time.perf_counter() - t_start\n",
    "gpu_time = None\n",
    "used_time[\"deep_pavlov\"] = (cpu_time, gpu_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/ai-forever/sage.git\n",
    "# cd sage\n",
    "# ! pip install .\n",
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "model_names = [\n",
    "    'ai-forever/RuM2M100-1.2B',\n",
    "    'ai-forever/RuM2M100-418M',\n",
    "    'ai-forever/FRED-T5-large-spell',\n",
    "    'ai-forever/T5-large-spell',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fixed_from_samples(model, tokenizer, samples, device='cpu', prefix=''):\n",
    "    samples_copy = [prefix + s for s in samples]\n",
    "    model = model.to(device)\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    tokens = tokenizer(samples_copy, padding=True, return_tensors='pt')\n",
    "    output = model.generate(tokens['input_ids'].to(device), do_sample=True, top_k=50, top_p=0.95, num_return_sequences=1)\n",
    "    results = tokenizer.batch_decode(output.cpu(), skip_special_tokens=True)\n",
    "\n",
    "    all_time = time.perf_counter() - t_start\n",
    "    return dict(zip(samples, results)), all_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                  | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████                                                     | 2/4 [00:34<00:32, 16.27s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/stanislav.petrov/.venvs/spell/lib64/python3.8/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:55<00:00, 13.88s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_name in tqdm(model_names):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    prefix = \"Исправь: \" if model_name == \"ai-forever/FRED-T5-large-spell\" else \"\"\n",
    "\n",
    "    _, time_for_gen_cpu = generate_fixed_from_samples(model, tokenizer, samples, device='cpu', prefix=prefix)\n",
    "\n",
    "    fixed_samples, time_for_gen_gpu = generate_fixed_from_samples(model, tokenizer, samples, device=device, prefix=prefix)\n",
    "\n",
    "    used_time[model_name] = (time_for_gen_cpu, time_for_gen_gpu)\n",
    "    results[model_name] = fixed_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu: ms</th>\n",
       "      <th>gpu: ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deep_pavlov</th>\n",
       "      <td>47.143819</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-1.2B</th>\n",
       "      <td>1904.489029</td>\n",
       "      <td>187.972296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-418M</th>\n",
       "      <td>1295.493372</td>\n",
       "      <td>110.247526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/FRED-T5-large-spell</th>\n",
       "      <td>748.755808</td>\n",
       "      <td>143.176129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/T5-large-spell</th>\n",
       "      <td>815.866127</td>\n",
       "      <td>101.259522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cpu: ms     gpu: ms\n",
       "deep_pavlov                       47.143819         NaN\n",
       "ai-forever/RuM2M100-1.2B        1904.489029  187.972296\n",
       "ai-forever/RuM2M100-418M        1295.493372  110.247526\n",
       "ai-forever/FRED-T5-large-spell   748.755808  143.176129\n",
       "ai-forever/T5-large-spell        815.866127  101.259522"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_used_time = pd.DataFrame(used_time, index=[\"cpu: ms\", \"gpu: ms\"]).T / len(samples) * 1000\n",
    "df_used_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu: rps</th>\n",
       "      <th>gpu: rps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deep_pavlov</th>\n",
       "      <td>21.211688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-1.2B</th>\n",
       "      <td>0.525075</td>\n",
       "      <td>5.319933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-418M</th>\n",
       "      <td>0.771907</td>\n",
       "      <td>9.070498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/FRED-T5-large-spell</th>\n",
       "      <td>1.335549</td>\n",
       "      <td>6.984405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/T5-large-spell</th>\n",
       "      <td>1.225691</td>\n",
       "      <td>9.875614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 cpu: rps  gpu: rps\n",
       "deep_pavlov                     21.211688       NaN\n",
       "ai-forever/RuM2M100-1.2B         0.525075  5.319933\n",
       "ai-forever/RuM2M100-418M         0.771907  9.070498\n",
       "ai-forever/FRED-T5-large-spell   1.335549  6.984405\n",
       "ai-forever/T5-large-spell        1.225691  9.875614"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rps = 1.0 / (df_used_time / 1000)\n",
    "df_rps.columns = [\"cpu: rps\", \"gpu: rps\"]\n",
    "df_rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE: пквкая чейчс погаа\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: пквкая чейчс погас\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: Дышать какая сейчас погода\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: .. Pokвская, чей час погана.\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: Лепковская сейчас пока что.Репковская сейчас пока что:1. Лупковская\n",
      "ai-forever/T5-large-spell\tOUTPUT: kobrвoka kobrвa\n",
      "######################################################################################################################################################\n",
      "SAMPLE: как проайти ло музея\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: как пройти до музея\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: apart как пройти до музея\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: Как пройти по Музея\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: как пройти до музея. как пройти до музея. как пройти до музея. как пройти до музея\n",
      "ai-forever/T5-large-spell\tOUTPUT: кака как podabaти ло ryryе\n",
      "######################################################################################################################################################\n",
      "SAMPLE: как папасть на сайт однакласники\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: как попасть на сайт однакласники\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: как попасть на сайт одноклассники\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: Как попасть на сайт «Одноклассники»\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: как попасть на сайт одноклассники.ру как попасть на сайт одноклассники.ру ьб\n",
      "ai-forever/T5-large-spell\tOUTPUT: кака alaaugri на сат од\n",
      "######################################################################################################################################################\n",
      "SAMPLE: кто еапичл картмну зевденая очь\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: кто еапичл картину зевденая дочь\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: return кто написал картину зеленая ночь\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: .. Кто напичл картину «Зеденая ночь».\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: Кто написал картину Звездная ночь»1. Кто написал картину Звездная ночь»2. Кто\n",
      "ai-forever/T5-large-spell\tOUTPUT: кkham kokholmy obedyrkh\n",
      "######################################################################################################################################################\n",
      "SAMPLE: прийдя в МГТУ я был удивлен никого необноружив там...\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: придя в моту я был удивлен никого необноружив там...\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: Secret прийдя в МГТУ я был удивлен никого необноружив там...\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: Прийдя в МГТУ, я был удивлен, никого не обнаружив там...\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: прийдя в МГТУ я был удивлен никого не обнаружив там...прийдя в МГ\n",
      "ai-forever/T5-large-spell\tOUTPUT: рида в   л yдeри\n",
      "######################################################################################################################################################\n",
      "SAMPLE: Думю ешцъа лет череа 10 ретроспективно просматривотьэ то будкетцц мне невероя тна ин те р но\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: думы ешцъа лет через 10 ретроспективно просматривотьэ то будкетцц мне неверия на ин те р но\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: apart Думаю что лет через 10 ретроспективно просматривать это будет мне невероятно интересно\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: .. Думаю, 6 лет через 10 ретроспективно просматривать это будет ЦЦЦ. Мне невероятно на интер, но.\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: Думаю ещё лет через 10 ретроспективно просматривать это будет мне невероятно интересно» Думаю это будет\n",
      "ai-forever/T5-large-spell\tOUTPUT: yyykl ea лет epe\n",
      "######################################################################################################################################################\n",
      "SAMPLE: crjkmrj ctqxfc dhtvtyb\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: crjkmrj ctqxfc dhtvtyb\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: drawings crjkmrj ctqxfc dhtvtyb\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: com/rjkmrj. co/tqxfcdHTvTyB.\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: crjkmrj ctqxfc dhtvtyb4\n",
      "ai-forever/T5-large-spell\tOUTPUT: The church also serves as the cathedral\n",
      "######################################################################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "to_print = defaultdict(dict)\n",
    "for model_name in results:\n",
    "    for sample in samples:\n",
    "        to_print[sample].update({model_name: results[model_name][sample]})\n",
    "\n",
    "str_result = \"\"\n",
    "for sample in to_print:\n",
    "    str_result += f\"SAMPLE: {sample}\\n\\n\"\n",
    "    for model_name, fixed in to_print[sample].items():\n",
    "        str_result += f\"{model_name}\"\n",
    "        if model_name == 'deep_pavlov':\n",
    "            str_result += '\\t'*2\n",
    "        str_result += f\"\\tOUTPUT: {fixed}\\n\"\n",
    "    str_result += '#' * 150 + '\\n'\n",
    "\n",
    "\n",
    "print(str_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
